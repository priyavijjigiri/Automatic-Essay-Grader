{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import nltk\n",
    "import nltk.data\n",
    "import re\n",
    "import tensorflow as tf\n",
    "import logging\n",
    "from __future__ import print_function\n",
    "from gensim.models import word2vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.stats import spearmanr\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from time import time\n",
    "from matplotlib.pyplot import cm\n",
    "from __future__ import print_function\n",
    "import timeit\n",
    "from textblob import TextBlob\n",
    "from textblob import Word\n",
    "import matplotlib.cm as cm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNN\n",
    "from sklearn.tree import DecisionTreeClassifier as DecisionTree\n",
    "from sklearn.ensemble import RandomForestClassifier as RandomForest\n",
    "from sklearn import grid_search\n",
    "from sklearn.svm import SVC\n",
    "import warnings\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here the given data set has 6 variables.\n",
    "1. essay_id\n",
    "2. essay_set\n",
    "3. essay\n",
    "4. rater1_domain1\n",
    "5. rater2_domain2\n",
    "6. domain1_score\n",
    "\n",
    "Out of these 5 variables only essay_set and Essay are responsible for grading."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "GlobalEnglish = pd.read_csv('globalenglish_essay_scoring.csv',encoding='ISO-8859-1')\n",
    "GlobalEnglish = GlobalEnglish[GlobalEnglish['domain1_score']<61]\n",
    "\n",
    "essay_sets = np.unique(GlobalEnglish['essay_set'])\n",
    "GlobalEnglish = GlobalEnglish.dropna(axis = 1)\n",
    "GlobalEnglish = GlobalEnglish.drop('rater1_domain1', 1)\n",
    "GlobalEnglish = GlobalEnglish.drop('rater2_domain1', 1)\n",
    "GlobalEnglish = GlobalEnglish.drop('essay_id', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.0\n",
      "6.0\n",
      "3.0\n",
      "3.0\n",
      "4.0\n",
      "4.0\n",
      "24.0\n",
      "60.0\n"
     ]
    }
   ],
   "source": [
    "for i in essay_sets:\n",
    "    print(np.max(GlobalEnglish.loc[GlobalEnglish[GlobalEnglish['essay_set'] == i].index.tolist(), 'domain1_score']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in essay_sets:\n",
    "    indices = GlobalEnglish[GlobalEnglish['essay_set'] == i].index.tolist()\n",
    "    maximum_grade = np.max(GlobalEnglish.loc[indices, 'domain1_score'])\n",
    "    minimum_grade = np.min(GlobalEnglish.loc[indices, 'domain1_score'])\n",
    "    GlobalEnglish.loc[indices, 'domain1_score_12'] = 12*(GlobalEnglish.loc[indices, 'domain1_score'] - minimum_grade)/(maximum_grade - minimum_grade)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyadarshinivijjigiri/anaconda2/lib/python2.7/site-packages/numpy/core/fromnumeric.py:57: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "  return getattr(obj, method)(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(GlobalEnglish['essay'], GlobalEnglish['domain1_score_12'], test_size=0.10)\n",
    "y_train = np.reshape(y_train,(len(y_train), 1))\n",
    "y_test = np.reshape(y_test, (len(y_test), 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essays are generally not graded on agreement or disagrement but rather depends on the statements. So we are removing the stop words in each essay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_list(sentence):\n",
    "    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence)\n",
    "    words = sentence.lower().split()    \n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    return ([w for w in words if not w in stops])\n",
    "\n",
    "tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "\n",
    "def essay_to_sentences(essay_v):\n",
    "    raw_sentences = tokenizer.tokenize(essay_v.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(sentence_to_list(raw_sentence))\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing sentences from all the Essays\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "\n",
    "print (\"Parsing sentences from all the Essays\")\n",
    "for essay_v in GlobalEnglish[\"essay\"]:\n",
    "    sentences += essay_to_sentences(essay_v)\n",
    "    \n",
    "print (\"Complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I got list of words for each essay and now I have built a model(word_to_vector_model) that converts each word into vector using word2vec package.\n",
    "I have taken 300 dimensional vector for each word, I have also taken 3 more parameters in creating this model.\n",
    "1. Minimum word count\n",
    "2. Context\n",
    "3. Number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dimensions = 300 \n",
    "min_word_count = 40\n",
    "num_workers = 4\n",
    "context = 10\n",
    "downsampling = 1e-3\n",
    "\n",
    "word_to_vector_model = word2vec.Word2Vec(sentences, workers=num_workers, size=dimensions, min_count = min_word_count, window = context, sample = downsampling)\n",
    "word_to_vector_model.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here I had converted each essay into a feature vector of dimension 300 by taking average of feature vectors of each and everyword present in the essay except the stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFeatureVec(words, model, num_features):\n",
    "    featureVec = np.zeros((num_features,),dtype=\"float32\")\n",
    "    nwords = 0.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            featureVec = np.add(featureVec,model[word])        \n",
    "    featureVec = np.divide(featureVec,nwords)\n",
    "    return featureVec\n",
    "\n",
    "def getAvgFeatureVecs(essays, model, num_features):\n",
    "    counter = 0\n",
    "    essayFeatureVecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for essay in essays:\n",
    "        essayFeatureVecs[counter] = makeFeatureVec(essay, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return essayFeatureVecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating average feature vecs for Training Essays\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyadarshinivijjigiri/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "print (\"Creating average feature vecs for Training Essays\")\n",
    "clean_train_essays = []\n",
    "for essay_v in X_train:\n",
    "    clean_train_essays.append( sentence_to_list( essay_v))\n",
    "trainDataVecs = getAvgFeatureVecs( clean_train_essays, word_to_vector_model, dimensions )\n",
    "\n",
    "\n",
    "clean_test_essays = []\n",
    "for essay_v in X_test:\n",
    "    clean_test_essays.append( sentence_to_list( essay_v ))\n",
    "testDataVecs = getAvgFeatureVecs( clean_test_essays, word_to_vector_model, dimensions )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To store results\n",
    "times = []\n",
    "scores = []\n",
    "labels = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I had built a logistic model using sklearn and GridSearchCv methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lab_enc = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/priyadarshinivijjigiri/anaconda2/lib/python2.7/site-packages/sklearn/cross_validation.py:553: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of labels for any class cannot be less than n_folds=3.\n",
      "  % (min_labels, self.n_folds)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'penalty': 'l1', 'class_weight': None}\n"
     ]
    }
   ],
   "source": [
    "parameters = {'class_weight': ['balanced', None], 'penalty': ['l1','l2']}\n",
    "logreg = LogisticRegression()\n",
    "log_grid = grid_search.GridSearchCV(logreg, parameters)\n",
    "log_grid.fit(trainDataVecs, lab_enc.fit_transform(y_train[:,0]))\n",
    "print (log_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_lr = time()\n",
    "logreg = LogisticRegression(penalty = 'l1', class_weight = None)\n",
    "logreg.fit(trainDataVecs,lab_enc.fit_transform(y_train[:,0]))\n",
    "preds_lr  = logreg.predict(testDataVecs)\n",
    "tot_lr = time() - start_lr\n",
    "\n",
    "scores.append(spearmanr(y_test, preds_lr)[0])\n",
    "times.append(tot_lr)\n",
    "labels.append('Log Reg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_knn = time()\n",
    "knn = KNN(n_neighbors = 16)\n",
    "knn.fit(trainDataVecs, lab_enc.fit_transform(y_train[:,0]))\n",
    "predsknn = knn.predict(testDataVecs)\n",
    "tot_knn = time() - start_knn\n",
    "\n",
    "scores.append(spearmanr(y_test, predsknn)[0])\n",
    "times.append(tot_knn)\n",
    "labels.append('KNN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time()\n",
    "svm = SVC(C = 50, gamma = 0.9)\n",
    "svm.fit(trainDataVecs,lab_enc.fit_transform(y_train[:,0]))\n",
    "predictions = svm.predict(testDataVecs)\n",
    "total = time() - start\n",
    "\n",
    "scores.append(spearmanr(y_test, predictions)[0])\n",
    "times.append(total)\n",
    "labels.append('SVM')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_rf = time()\n",
    "rf = RandomForest(n_estimators = 51, max_depth = 14)\n",
    "rf.fit(trainDataVecs, lab_enc.fit_transform(y_train[:,0]))\n",
    "preds_rf = rf.predict(testDataVecs)\n",
    "tot_rf = time() - start_rf \n",
    "\n",
    "scores.append(spearmanr(y_test, preds_rf)[0])\n",
    "times.append(tot_rf)\n",
    "labels.append('Random Forest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAdYAAAG5CAYAAAAzuBXVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBAUSG2sQBEEQFMjfuszu5Gd2tZ4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a3169b750>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.cm as cm\n",
    "#plot\n",
    "fig = plt.figure(figsize=(7,7))\n",
    "\n",
    "color=iter(cm.rainbow(np.linspace(0,1,4,3)))\n",
    "for label, x, y, col  in zip(labels, scores, times, color):\n",
    "    plt.scatter(x, y, color=col, s = 50)\n",
    "    plt.grid(color='k')\n",
    "    plt.annotate(\n",
    "    label,\n",
    "    xy = (x, y), xytext = (40, 20),\n",
    "    textcoords = 'offset points', ha = 'center', va = 'center',\n",
    "    bbox = dict(boxstyle = 'round,pad=0.5', fc = 'white', alpha = 0.5),\n",
    "    arrowprops = dict(arrowstyle = '->', connectionstyle = 'arc3,rad=0'))  \n",
    "plt.title('Computation Time Vs. Spearmans Correlation')\n",
    "plt.ylabel('Computation Time (Seconds)')\n",
    "plt.xlabel('Spearmans Correlation')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I choose a metric called Spearman correlation coefficient to assess my model. As we can see from the plot SVM gave the heighest Spearmans Correlation coefficent.\n",
    "where as its computation time is very high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I have built a deep Neural network which takes feature vector for each essay as input and predicts essay grade as output.\n",
    "\n",
    "First Hidden layer is of 500 neurons\n",
    "Second Hidden layer is of 750 neurons\n",
    "##### Activation function\n",
    "   Relu activation function is used to increase the non-linearity in the model.\n",
    "##### Optimizer\n",
    "   Adam optimizer with learning rate 0.001\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_matrix(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_matrix(shape):\n",
    "    initial = tf.zeros(shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 300\n",
    "hidden_nodes_1 = 500\n",
    "hidden_nodes_2 = 750\n",
    "size = testDataVecs.shape[1]\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "\n",
    "    # Input data.\n",
    "    with tf.name_scope(\"Input\"):\n",
    "        tf_train_dataset = tf.placeholder(tf.float32, shape=(batch_size, size))\n",
    "        tf_train_labels = tf.placeholder(tf.float32, shape=(batch_size, 1))\n",
    "    \n",
    "    tf_test_dataset = tf.constant(testDataVecs)\n",
    "      \n",
    "    layer1_weights = weight_matrix([size, hidden_nodes_1])\n",
    "    layer1_biases = bias_matrix([hidden_nodes_1]) \n",
    "    \n",
    "    layer2_weights = weight_matrix([hidden_nodes_1, hidden_nodes_2])\n",
    "    layer2_biases = bias_matrix([hidden_nodes_2])\n",
    "    \n",
    "    layer3_weights = weight_matrix([hidden_nodes_2, 1])\n",
    "    layer3_biases = bias_matrix([1])\n",
    "    \n",
    "    def model(data):\n",
    "        with tf.name_scope(\"Layer_1\"):\n",
    "            layer1 = tf.nn.relu(tf.matmul(data, layer1_weights) + layer1_biases)\n",
    "        \n",
    "        with tf.name_scope(\"Layer_2\"):\n",
    "            \n",
    "            layer2 = tf.nn.relu(tf.matmul(layer1, layer2_weights) + layer2_biases)\n",
    "\n",
    "        with tf.name_scope(\"Layer_3\"):\n",
    "            layer3 = tf.nn.relu(tf.matmul(layer2, layer3_weights) + layer3_biases)\n",
    "        return layer3\n",
    "    \n",
    "    yhat = model(tf_train_dataset)\n",
    "    \n",
    "    with tf.name_scope(\"Loss\"):\n",
    "        loss = tf.reduce_mean(tf.square(yhat - tf_train_labels))\n",
    "    \n",
    "\n",
    "    global_step = tf.Variable(0)  # count  number of steps taken.\n",
    "    start_learning_rate = 0.001\n",
    "    learning_rate = tf.train.exponential_decay(start_learning_rate, global_step, 100000, 0.96, staircase=True)\n",
    "    \n",
    "    with tf.name_scope(\"Train\"):\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    tf.summary.scalar(\"loss\", loss)\n",
    "    \n",
    "    # Predictions for the training, validation, and test data.\n",
    "    train_prediction = yhat\n",
    "    test_prediction = model(tf_test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialized\n",
      "Minibatch Loss at Epoch 0: 57.773\n",
      "Minibatch Spearman Score: 0.2224\n",
      "Minibatch Loss at Epoch 500: 3.669\n",
      "Minibatch Spearman Score: 0.7470\n",
      "Minibatch Loss at Epoch 1000: 3.281\n",
      "Minibatch Spearman Score: 0.7189\n",
      "Minibatch Loss at Epoch 1500: 3.081\n",
      "Minibatch Spearman Score: 0.7875\n",
      "Minibatch Loss at Epoch 2000: 2.584\n",
      "Minibatch Spearman Score: 0.7937\n",
      "Minibatch Loss at Epoch 2500: 2.517\n",
      "Minibatch Spearman Score: 0.8197\n",
      "Minibatch Loss at Epoch 3000: 1.870\n",
      "Minibatch Spearman Score: 0.8637\n",
      "Minibatch Loss at Epoch 3500: 1.723\n",
      "Minibatch Spearman Score: 0.8857\n",
      "Minibatch Loss at Epoch 4000: 1.788\n",
      "Minibatch Spearman Score: 0.8723\n",
      "Minibatch Loss at Epoch 4500: 2.180\n",
      "Minibatch Spearman Score: 0.8531\n",
      "Minibatch Loss at Epoch 5000: 1.496\n",
      "Minibatch Spearman Score: 0.8942\n",
      "Test Spearman Score: 0.8942\n"
     ]
    }
   ],
   "source": [
    "test_preds = pd.DataFrame()\n",
    "# Re-define the function to include the keep probability\n",
    "l_array = []\n",
    "start = timeit.timeit()\n",
    "num_epochs = 5001\n",
    "def run_session(num_epochs, name):\n",
    "    with tf.Session(graph=graph) as session:\n",
    "        writer = tf.summary.FileWriter(\"logs/\", session.graph)\n",
    "        tf.initialize_all_variables().run()\n",
    "        print(\"Initialized\")\n",
    "        for epoch in range(num_epochs):\n",
    "            offset = (epoch * batch_size) % (y_train.shape[0] - batch_size)\n",
    "            batch_data = trainDataVecs[offset:(offset + batch_size), :]\n",
    "            batch_labels = y_train[offset:(offset + batch_size)]\n",
    "            feed_dict = {tf_train_dataset : batch_data, tf_train_labels : batch_labels}\n",
    "            _, l, predictions = session.run([optimizer, loss, train_prediction], feed_dict=feed_dict)\n",
    "            l_array.append(l)\n",
    "            if (epoch % 500 == 0):\n",
    "                print(\"Minibatch Loss at Epoch {}: {:.3f}\".format(epoch, l))\n",
    "                rho, pval = (spearmanr(predictions, batch_labels))\n",
    "                print(\"Minibatch Spearman Score: {:.4f}\".format(rho))\n",
    "        final_rho, pval = spearmanr(test_prediction.eval(), y_test)\n",
    "        print(\"Test Spearman Score: {:.4f}\".format(rho))\n",
    "        scores.append(final_rho)\n",
    "        test_preds[name] = test_prediction.eval().ravel()\n",
    "        filesave = np.zeros((len(y_test), 2))\n",
    "        to_use = test_prediction.eval()\n",
    "        \n",
    "        for ii in range(len(y_test)):           \n",
    "            filesave[ii, 0] = y_test[ii]\n",
    "            filesave[ii, 1] = to_use[ii]\n",
    "        \n",
    "        np.savetxt('savetest.txt', filesave, delimiter=\",\", fmt=\"%d\") \n",
    "        \n",
    "run_session(num_epochs, \"Deep_NN\")\n",
    "total = timeit.timeit() - start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Deep Neural Network Spearman correlation coefficient is further increased to 0.89. which proves that DNN works better than every model tried."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
